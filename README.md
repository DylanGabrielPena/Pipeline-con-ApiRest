Ecommerce Data Pipeline
Pipeline automatizado ETL (Extract, Transform, Load) desarrollado en Python para extraer datos de ventas de una API, transformarlos con Pandas y almacenarlos en formato Parquet particionado de manera eficiente.

ğŸ“‚ Estructura del Proyecto
Plaintext
proyecto/

â”œâ”€â”€ config.py           # ConfiguraciÃ³n (API Keys, URLs, constantes)

â”œâ”€â”€ main.py             # CÃ³digo principal del pipeline (ETL)

â”œâ”€â”€ output/             # Directorio generado automÃ¡ticamente

â”‚   â””â”€â”€ orders/         # Datos guardados particionados

â”‚       â”œâ”€â”€ order_year=2025/

â”‚       â”‚   â””â”€â”€ order_month=11/

â”‚       â”‚       â””â”€â”€ part-0.parquet

â”‚       â””â”€â”€ ...

â””â”€â”€ requirements.txt    # LibrerÃ­as necesarias (pandas, requests, etc.)

ğŸš€ Funcionalidades
1. ExtracciÃ³n Robusta (Extract)
ConexiÃ³n a API REST segura mediante requests.

Sistema de Reintentos Inteligente: Implementa una estrategia de exponential backoff para manejar fallos de red o errores 5xx del servidor.

Manejo de excepciones especÃ­ficas (Timeout, HTTPError, RequestException).

2. TransformaciÃ³n de Datos (Transform)
ConversiÃ³n de JSON anidado a DataFrame de Pandas.

Limpieza de Fechas: NormalizaciÃ³n de columnas de tiempo (order_date) eliminando horas innecesarias (00:00:00), manteniendo el tipo datetime64 para optimizaciÃ³n.

Enriquecimiento: CreaciÃ³n automÃ¡tica de columnas order_year y order_month para la estrategia de particionado.

3. Carga Optimizada (Load)
Almacenamiento en formato Parquet (columnar y comprimido).

Particionado Hive-Style: Los datos se guardan organizados en carpetas jerÃ¡rquicas por AÃ±o y Mes (year=X/month=Y) para optimizar futuras consultas y lecturas parciales.

ğŸ› ï¸ Requisitos Previos
Python 3.8+

LibrerÃ­as listadas en requirements.txt:

Plaintext
pandas
requests
pyarrow
fastparquet (opcional, para engine de parquet)
âš™ï¸ ConfiguraciÃ³n
AsegÃºrate de tener un archivo config.py en la raÃ­z con tus credenciales:

Python
# config.py
API_KEY = "tu_api_key"
API_EMAIL = "tu_email"
API_BASE_URL = "https://api.tudominio.com"
â–¶ï¸ EjecuciÃ³n
Para correr el pipeline completo:

Bash
python main.py
El script generarÃ¡ logs detallados en la consola indicando el progreso de la extracciÃ³n, la cantidad de filas procesadas y la ubicaciÃ³n final de los archivos.
